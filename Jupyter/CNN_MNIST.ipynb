{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bead653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3f7194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "mnist=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60188442",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)=mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54381e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images,test_images=train_images/255.0,test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9299afdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008ab1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01a5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "num_classes=10\n",
    "train_labels=to_categorical(train_labels,num_classes)\n",
    "test_labels=to_categorical(test_labels,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf3fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width=28\n",
    "input_height=28\n",
    "input_channels=1\n",
    "input_pixels=784\n",
    "\n",
    "n_conv1=32\n",
    "n_conv2=64\n",
    "stride_conv1=1\n",
    "stride_conv2=1\n",
    "conv1_k=5\n",
    "conv2_k=5\n",
    "max_pool1_k=2\n",
    "max_pool2_k=2\n",
    "\n",
    "n_hidden=1024\n",
    "n_out=10\n",
    "\n",
    "input_size_to_hidden=(input_width//(max_pool1_k*max_pool2_k))*(input_height//(max_pool1_k*max_pool2_k))*n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaadd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={\n",
    "    \"wc1\":tf.Variable(tf.random.normal([conv1_k,conv1_k,input_channels,n_conv1])),\n",
    "     \"wc2\":tf.Variable(tf.random.normal([conv2_k,conv2_k,n_conv1,n_conv2])),\n",
    "     \"wh1\":tf.Variable(tf.random.normal([input_size_to_hidden,n_hidden])),\n",
    "     \"wo\":tf.Variable(tf.random.normal([n_hidden,n_out]))\n",
    "}\n",
    "biases={\n",
    "    \"bc1\":tf.Variable(tf.random.normal([n_conv1])),\n",
    "    \"bc2\":tf.Variable(tf.random.normal([n_conv2])),\n",
    "    \"bh1\":tf.Variable(tf.random.normal([n_hidden])),\n",
    "    \"bo\":tf.Variable(tf.random.normal([n_out])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78038e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x,weights,bias,strides=1):\n",
    "    out=tf.nn.conv2d(x,weights,padding=\"SAME\",strides=[1,strides,strides,1])\n",
    "    out=tf.nn.bias_add(out,bias)\n",
    "    out=tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def maxpooling(x,k=2):\n",
    "    return tf.nn.max_pool(x,padding=\"SAME\",ksize=[1,k,k,1],strides=[1,k,k,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a3ee074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x,weights,biases):\n",
    "    x=tf.reshape(x,shape=[-1,input_height,input_width,input_channels])\n",
    "    conv1=conv(x,weights['wc1'],biases['bc1'],stride_conv1)\n",
    "    conv1_pool=maxpooling(conv1,max_pool1_k)\n",
    "    \n",
    "    conv2=conv(conv1_pool,weights['wc2'],biases['bc2'],stride_conv2)\n",
    "    conv2_pool=maxpooling(conv2,max_pool2_k)\n",
    "    \n",
    "    hidden_input=tf.reshape(conv2_pool,shape=[-1,input_size_to_hidden])\n",
    "    hidden_output_before_activation=tf.add(tf.linalg.matmul(hidden_input,weights['wh1'],biases['bh1']))\n",
    "    hidden_output=tf.nn.relu(hidden_output_before_activation)\n",
    "    \n",
    "    output=tf.add(tf.matmul(hidden_output,weights['w0']),biases['bo'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2130403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.conv2d), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(5, 5, 1, 32) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.conv2d_1), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(5, 5, 32, 64) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_1), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "Exception encountered when calling layer \"tf.linalg.matmul\" (type TFOpLambda).\n\nUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n\nCall arguments received by layer \"tf.linalg.matmul\" (type TFOpLambda):\n  • a=tf.Tensor(shape=(None, 3136), dtype=float32)\n  • b=<tf.Variable 'Variable:0' shape=(3136, 1024) dtype=float32>\n  • transpose_a=<tf.Variable 'Variable:0' shape=(1024,) dtype=float32>\n  • transpose_b=False\n  • adjoint_a=False\n  • adjoint_b=False\n  • a_is_sparse=False\n  • b_is_sparse=False\n  • output_type=None\n  • name=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(input_pixels,))\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(n_out,))\n\u001b[1;32m----> 3\u001b[0m pred\u001b[38;5;241m=\u001b[39m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m, in \u001b[0;36mcnn\u001b[1;34m(x, weights, biases)\u001b[0m\n\u001b[0;32m      7\u001b[0m conv2_pool\u001b[38;5;241m=\u001b[39mmaxpooling(conv2,max_pool2_k)\n\u001b[0;32m      9\u001b[0m hidden_input\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mreshape(conv2_pool,shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,input_size_to_hidden])\n\u001b[1;32m---> 10\u001b[0m hidden_output_before_activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39madd(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwh1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbh1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m hidden_output\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(hidden_output_before_activation)\n\u001b[0;32m     13\u001b[0m output\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mmatmul(hidden_output,weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw0\u001b[39m\u001b[38;5;124m'\u001b[39m]),biases[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbo\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\tf_op_layer.py:119\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(x, keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor)\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([args, kwargs])\n\u001b[0;32m    118\u001b[0m ):\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTFOpLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: Exception encountered when calling layer \"tf.linalg.matmul\" (type TFOpLambda).\n\nUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n\nCall arguments received by layer \"tf.linalg.matmul\" (type TFOpLambda):\n  • a=tf.Tensor(shape=(None, 3136), dtype=float32)\n  • b=<tf.Variable 'Variable:0' shape=(3136, 1024) dtype=float32>\n  • transpose_a=<tf.Variable 'Variable:0' shape=(1024,) dtype=float32>\n  • transpose_b=False\n  • adjoint_a=False\n  • adjoint_b=False\n  • a_is_sparse=False\n  • b_is_sparse=False\n  • output_type=None\n  • name=None"
     ]
    }
   ],
   "source": [
    "x = tf.keras.layers.Input(shape=(input_pixels,))\n",
    "y = tf.keras.layers.Input(shape=(n_out,))\n",
    "pred=cnn(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450973d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
